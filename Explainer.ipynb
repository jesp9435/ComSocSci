{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to investigate, how rain may affect the tips received by yellow taxi drivers, but also use the text from wikipedia to explain, why some places are more attractive than others in New York City.\n",
    "\n",
    "In this project, we have 3 data sets: TLC trip record data, weather data in New York City scraped from wunderground and text scraped from Wikipedia. Details on the data will be explained now:\n",
    "\n",
    "TLC trip record data is yellow and green taxi trip records on fields including: tip, pick-up location/time and drop-off location/time. The data is accessible from the following link: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page and you are able to download yellow and green taxi trip records for a given month between 2009 and 2024. The data downloaded from the website is in a format called Parquet, which can be imported into a panda dataframe easily. The locations are seperated into taxi zones, and the information regarding these can be downloaded from the same website. \n",
    "\n",
    "We chose to scrape the weather data from wunderground, because the website keeps weather history data, you can choose specific weather stations in New York City and finally, it was relatively easy to scrape due to the format of the url. This website uses JavaScript, so BeautifulSoup did not suffice and we resolved to another method using Selenium to scrape. The data we scraped came in tables, where the precipitation, wind, temperature and other weather relevant fields were recorded hourly from 1930 to 2024. There are many weather stations in New York City, so we resolved to using the default weather station with initials KLGA. The website has the following link: https://www.wunderground.com/history/daily/us/ny/new-york-city/KLGA/date/, where the data needs to be inputted after date/. \n",
    "\n",
    "To get a deeper insight into, why people take taxi trips from one location to another, we categorized the pick-up and drop-off locations based on the borough the taxi zones are in. Based on the 5 boroughs in New York City: Manhattan, Bronx, Staten Island, Brooklyn and Queens, we scraped their respective wikipedia page and also wikipedia pages of locations of interest (that ware on the boroughs' pages) to retrieve as much information as possible. \n",
    "\n",
    "Based on some simple google search, the month of May is the month with the most inconsistency in the weather, that is 9 days on average are rainy and the remaining are not. We chose to look at the 10 previous years in the month of May, and found that May 5th in 2017 and 2013 have the greatest difference in precipitation. These 2 days are the ones we will be focussing on in this report.\n",
    "\n",
    "The intended goal for the end user's experience is to get an insight on what may influence people to tip taxi drivers. As a taxi driver, it may suggests where you should go when it rains and when it does not rain. Furthermore, it may also suggest which routes you should not take to maximize tips received. For policy makers, it may suggest boroughs, where public transportation availability may need to be improved. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from bs4 import BeautifulSoup  \n",
    "import json\n",
    "import pandas as pd\n",
    "import concurrent.futures \n",
    "import requests\n",
    "import math\n",
    "import csv\n",
    "from collections import Counter\n",
    "import ast\n",
    "import netwulf as nw\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import wordcloud\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import netwulf as nw\n",
    "import matplotlib.pyplot as plt\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write about your choices in data cleaning and preprocessing\n",
    "\n",
    "Write a short section that discusses the dataset stats (here you can recycle the work you did for Project Assignment A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tools, theory and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
