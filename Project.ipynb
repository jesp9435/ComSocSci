{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID2023', 'tpep_pickup_datetime2023', 'tpep_dropoff_datetime2023',\n",
      "       'passenger_count2023', 'trip_distance2023', 'RatecodeID2023',\n",
      "       'store_and_fwd_flag2023', 'PULocationID2023', 'DOLocationID2023',\n",
      "       'payment_type2023',\n",
      "       ...\n",
      "       'payment_type2013', 'fare_amount2013', 'extra2013', 'mta_tax2013',\n",
      "       'tip_amount2013', 'tolls_amount2013', 'improvement_surcharge2013',\n",
      "       'total_amount2013', 'congestion_surcharge2013', 'airport_fee2013'],\n",
      "      dtype='object', length=209)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "# Read in the data\n",
    "df_2023 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2023-05.parquet\")\n",
    "df_2022 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2022-05.parquet\")\n",
    "df_2021 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2021-05.parquet\")\n",
    "df_2020 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2020-05.parquet\")\n",
    "df_2019 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2019-05.parquet\")\n",
    "df_2018 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2018-05.parquet\")\n",
    "df_2017 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2017-05.parquet\")\n",
    "df_2016 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2016-05.parquet\")\n",
    "df_2015 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2015-05.parquet\")\n",
    "df_2014 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2014-05.parquet\")\n",
    "df_2013 = pd.read_parquet(\"/Users/jesperberglund/Desktop/TaxiDataMay/yellow_tripdata_2013-05.parquet\")\n",
    "\n",
    "# Rename columns to include year for each dataframe and concatenate them into one dataframe with all years\n",
    "dataframes = [df_2023, df_2022, df_2021, df_2020, df_2019, df_2018, df_2017, df_2016, df_2015, df_2014, df_2013]\n",
    "years = [2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013]\n",
    "for df, year in zip(dataframes, years):\n",
    "    df.columns = [f'{col}{year}' for col in df.columns]\n",
    "df_total = pd.concat(dataframes, axis=1)\n",
    "\n",
    "print(df_total.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export a random sample of 100,000 rows to a csv file\n",
    "columns_to_export = [f'{col}{year}' for year in years for col in ['tip_amount', 'tpep_pickup_datetime', 'PULocationID', 'DOLocationID']]\n",
    "# The length of the \"shortest\" column is 2507109:\n",
    "print(len(df_2021['tip_amount2021']))\n",
    "random_indices = np.sort(np.random.choice(2507109, size=100_000, replace=False))\n",
    "df_total[columns_to_export].iloc[random_indices].to_csv('df_tip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0c/bp6_ntbd5rj6j3w7h1dg5xvm0000gn/T/ipykernel_42983/2819314562.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_5th_may_2013['tpep_pickup_datetime2013'] = pd.to_datetime(df_5th_may_2013['tpep_pickup_datetime2013'])\n",
      "/var/folders/0c/bp6_ntbd5rj6j3w7h1dg5xvm0000gn/T/ipykernel_42983/2819314562.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_5th_may_2017['tpep_pickup_datetime2017'] = pd.to_datetime(df_5th_may_2017['tpep_pickup_datetime2017'])\n"
     ]
    }
   ],
   "source": [
    "# 5. maj 2013 og 2017\n",
    "df_5th_may_2013 = df_2013[['tip_amount2013', 'PULocationID2013', 'DOLocationID2013', 'tpep_pickup_datetime2013']]\n",
    "df_5th_may_2017 = df_2017[['tip_amount2017','PULocationID2017', 'DOLocationID2017', 'tpep_pickup_datetime2017']]\n",
    "\n",
    "# Convert 'tpep_pickup_datetime' columns to datetime\n",
    "df_5th_may_2013['tpep_pickup_datetime2013'] = pd.to_datetime(df_5th_may_2013['tpep_pickup_datetime2013'])\n",
    "df_5th_may_2017['tpep_pickup_datetime2017'] = pd.to_datetime(df_5th_may_2017['tpep_pickup_datetime2017'])\n",
    "\n",
    "# Filter rows where day is 5 for both 2013 and 2017\n",
    "df_5th_may_2013 = df_5th_may_2013[((df_5th_may_2013['tpep_pickup_datetime2013'].dt.day == 5))]\n",
    "df_5th_may_2017 = df_5th_may_2017[((df_5th_may_2017['tpep_pickup_datetime2017'].dt.day == 5))]\n",
    "\n",
    "# Export to csv\n",
    "df_5th_may_2013.to_csv('df_5th_may_2013.csv')\n",
    "df_5th_may_2017.to_csv('df_5th_may_2017.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create an empty graph\n",
    "G = nx.Graph()\n",
    "count = 0\n",
    "# Iterate over DataFrame rows\n",
    "for index, row in df_total.iterrows():\n",
    "    # Get the nodes and weight\n",
    "    pickup_location = row['PULocationID2014']\n",
    "    dropoff_location = row['DOLocationID2014']\n",
    "    tip_amount = row['tip_amount2014']\n",
    "    count += 1\n",
    "    print(count)\n",
    "    # If the edge already exists, add the tip amount to the weight\n",
    "    if G.has_edge(pickup_location, dropoff_location):\n",
    "        G[pickup_location][dropoff_location]['weight'] += tip_amount\n",
    "    # If the edge does not exist, create it and set the weight to the tip amount\n",
    "    else:\n",
    "        G.add_edge(pickup_location, dropoff_location, weight=tip_amount)\n",
    "\n",
    "\n",
    "# def make_pairs(temp_list):\n",
    "#     temp_list=list(temp_list)\n",
    "#     temp_list.sort()\n",
    "#     pairs=list(combinations(temp_list,2))\n",
    "#     return pairs\n",
    "\n",
    "# def count_pairs(author_list):\n",
    "#     unique_pairs = {}\n",
    "#     for author_pair in author_list:\n",
    "#         sorted_author_pair = sorted(author_pair)\n",
    "#         sorted_author_pair_tuple = tuple(sorted_author_pair)\n",
    "#         if sorted_author_pair_tuple in unique_pairs:\n",
    "#             unique_pairs[sorted_author_pair_tuple] += 1\n",
    "#         else:\n",
    "#             unique_pairs[sorted_author_pair_tuple] = 1\n",
    "#     unique_author_list = [[list(author_pair), count] for author_pair, count in unique_pairs.items()]\n",
    "#     return unique_author_list\n",
    "\n",
    "# G = nx.Graph()\n",
    "# # count = 0\n",
    "# # for pair in pairs:\n",
    "# #     G.add_edge(pair[0][0],pair[0][1],attr=pair[1])\n",
    "# #     count += 1\n",
    "# #     print(str(count) + \" : \"+str(len(pairs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ANN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e253e861da49e0bbccda70175bce74f3442aedb410e74d034432e289d13936b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
